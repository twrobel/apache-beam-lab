{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Windows - What are they good for?\n",
    "\n",
    "When we work on a _batch_ (e.g. a `.csv` file) we are dealing with a _bounded_ input. There are a finite number of records \n",
    "in our `PCollection`. Working with a bounded input comes naturally to most people, so much so that there are a number of \n",
    "concepts that we probably take for granted when doing so. For example, imagine you are processing a `.csv` file containing\n",
    "the scores that players recorded on an online game. The `.csv` file is published daily (the number of records in the file\n",
    "vary from one day to the next). Say you wanted to determine the average score for players aged 16-18? You could perform \n",
    "a `GroupByKey` operation on the `PCollection` records where the key `16 >= age <= 18` and calculate the `mean`. In this \n",
    "scenario, we usally assume that the `GroupByKey` operation will be performed on _all_ of the matching records in the \n",
    "`.csv` file.  \n",
    "\n",
    "Now consider an alternative scenario where the data arrives as a stream via a Kafka Topic. In this scenario our input is \n",
    "_unbounded_; there are an infinite (or potentially infinite) number of records in our `PCollection`. We can't  simply \n",
    "declare a `GroupByKey` operation on the stream where `16 >= age <= 18`, because these types of records could keep \n",
    "arriving forever (apparently, a lot of teenagers are playing video games these days). Instead, we also need to declare a\n",
    "_boundary_ on the data we want processed. Windows! Windows let us explicitly define boundaries on our input data. \n",
    "\n",
    "## Types of Windows\n",
    "\n",
    "### Fixed Time Windows (aka Tumbling Windows)\n",
    "\n",
    "Given a timestamped `PCollection` we declare a window to capture all of the elements whose timestamps lie within the \n",
    "specified time range. For example, we might declare a fixed window with a duration of 30 seconds on our stream data. \n",
    "Then, any elements with a timestamp in the range `[00:00:00, 00:00:30)` (i.e. up to but not including `00:00:30`) would \n",
    "get averaged as part of Window 0. Likewise, any elements with a timestamp in the range `[00:00:30, 00:01:00)` would get \n",
    "averaged as part of Window 1, and so on.  \n",
    "\n",
    "<table class=\"image\">\n",
    "<caption align=\"bottom\" style=\"text-align: center\">https://beam.apache.org/documentation/programming-guide</caption>\n",
    "<tr><td><img src=\"https://beam.apache.org/images/fixed-time-windows.png\"></td></tr>\n",
    "</table>\n",
    " \n",
    "### Sliding Time Windows\n",
    "\n",
    "Sliding windows can overlap. For example, we could declare a sliding window _duration_ of 60 seconds, and declare that a \n",
    "new window should start every 30 seconds (called the _period_). In this case, elements will belong to more than 1 \n",
    "window. This type of windowing can be used to create rolling averages.\n",
    "\n",
    "<table class=\"image\">\n",
    "<caption align=\"bottom\" style=\"text-align: center\">https://beam.apache.org/documentation/programming-guide</caption>\n",
    "<tr><td><img src=\"https://beam.apache.org/images/sliding-time-windows.png\"></td></tr>\n",
    "</table>\n",
    "\n",
    "### Session Windows\n",
    "\n",
    "A session window creates a boundary around a series of consecutive events separated by a duration of time (i.e. a\n",
    "_gap_). For example, imagine we are collecting user input data (e.g. keyboard strokes, joystick movement, touch input) \n",
    "for the players in our online game. We might expect to see bursts of data for each player, followed by gaps with no \n",
    "activity (time for a soda, time for homework). When data arrives after the specified gap duration, a new window is \n",
    "created. Note that session windows are applied on a per-key basis.   \n",
    "\n",
    "<table class=\"image\">\n",
    "<caption align=\"bottom\" style=\"text-align: center\">\n",
    "    https://beam.apache.org/documentation/programming-guide\n",
    "</caption>\n",
    "<tr><td><img src=\"https://beam.apache.org/images/session-windows.png\"></td></tr>\n",
    "</table>\n",
    "\n",
    "### Global Windows\n",
    "\n",
    "This is the default window if your pipeline doesn't explicitly create one of the aforementioned windows. When we \n",
    "considered our batch data example, we relied on a global window. Because our datasource was a `.csv` file, the data was \n",
    "bounded so we could safely perform aggregation operations (e.g. `GroupByKey`, `Combine`) operations. Actually, you _can_ \n",
    "use a global window on streaming data, under a couple of circumstances:\n",
    "\n",
    "- You aren't performing any aggregation operations in your pipeline. For example, if your pipeline is performing simple \n",
    "transformations on individual `PCollection` elements as they arrive on the stream. \n",
    "- You provide a non-default `Trigger` for the global window. Triggers are the mechanism used by Beam to determine when \n",
    "to emit the results of a window. So for example, you might use a custom trigger that says to emit the results of your \n",
    "global window every time 50 elements arrive.\n",
    "\n",
    "## References\n",
    "\n",
    "https://beam.apache.org/documentation/programming-guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}